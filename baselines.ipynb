{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67360df8",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac5e32a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'_target_': 'src.datasets.YambdaDataset', 'name': 'train', 'inter_type': 'listens', 'yambda_size': '50m', 'min_inter_user': 1000, 'min_inter_item': 10, 'min_len': 5, 'q': 0.95, 'max_len': 200, 'instance_transforms': '${transforms.instance_transforms.inference}'}, 'test': {'_target_': 'src.datasets.YambdaDataset', 'name': 'test', 'inter_type': '${..train.inter_type}', 'yambda_size': '${..train.yambda_size}', 'min_inter_user': '${..train.min_inter_user}', 'min_inter_item': '${..train.min_inter_item}', 'min_len': '${..train.min_len}', 'q': '${..train.q}', 'max_len': '${..train.max_len}', 'instance_transforms': '${transforms.instance_transforms.inference}'}}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "\n",
    "with initialize(version_base=None, config_path=\"./src/configs/datasets\"):\n",
    "    cfg = compose(config_name=\"sasrec\")\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3789b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'src.datasets.YambdaDataset'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = cfg[\"train\"]\n",
    "config[\"instance_transforms\"] = None\n",
    "config = dict(config)\n",
    "config[\"inactivity_thresh\"] = 30 * 60\n",
    "config.pop(\"_target_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfb06940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datasets import YambdaDataset\n",
    "\n",
    "train_dataset = YambdaDataset(**config)\n",
    "config[\"name\"] = \"test\"\n",
    "val_dataset = YambdaDataset(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c998f",
   "metadata": {},
   "source": [
    "# MRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c48eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10: 0.07359710460662708, COV@10: 0.45716593659192434\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "cnt = 0\n",
    "k = 10\n",
    "seen_items = set()\n",
    "\n",
    "for data in val_dataset:\n",
    "    values, counts = torch.unique(data[\"seq\"], return_counts=True)\n",
    "    top_k_indices = torch.argsort(counts, descending=True)[:k]\n",
    "    recs = values[top_k_indices]\n",
    "    seen_items |= set(recs.cpu().numpy())\n",
    "    if torch.any(recs == data[\"item\"]):\n",
    "        cnt += 1\n",
    "\n",
    "print(\n",
    "    f\"HR@{k}: {cnt / len(val_dataset)}, COV@{k}: {len(seen_items) / val_dataset.n_items}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7cc73d",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cc0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_dataset._df\n",
    "val_df = val_dataset._df\n",
    "holdout = val_df[~val_df.duplicated(subset=\"session_id\", keep=\"last\")]\n",
    "val_df = val_df[val_df.duplicated(subset=\"session_id\", keep=\"last\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d56bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import svds\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_mtx(df, user_col=\"uid\"):\n",
    "    return csr_matrix(\n",
    "        (np.ones(len(df)), (df[user_col], df[\"item_id\"])),\n",
    "        shape=(df[user_col].max() + 1, df[\"item_id\"].max() + 1),\n",
    "    )\n",
    "\n",
    "\n",
    "def metrics(recs, true):\n",
    "    k = recs.shape[1]\n",
    "    matches = recs == true.reshape(-1, 1)\n",
    "    ranks = np.full(recs.shape[0], k + 1)\n",
    "    found_mask = matches.any(axis=1)\n",
    "    if found_mask.any():\n",
    "        first_match_idx = matches.argmax(axis=1)\n",
    "        ranks[found_mask] = first_match_idx[found_mask] + 1\n",
    "    ideal_rank = 1\n",
    "    dcg = np.where(ranks <= k, 1.0 / np.log2(ranks + 1), 0.0)\n",
    "    idcg = 1.0 / np.log2(ideal_rank + 1)\n",
    "    ndcg_per_user = dcg / idcg\n",
    "    metrics = {\"ndcg\": np.mean(ndcg_per_user), \"hitrate\": np.mean(matches.any(axis=1))}\n",
    "    return metrics\n",
    "\n",
    "\n",
    "train_mtx = get_mtx(train_df)\n",
    "val_mtx = get_mtx(val_df, user_col=\"session_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53bde1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "u, s, vh = svds(train_mtx, k=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01f5ab53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56918"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[\"session_id\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "662b6173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 57/57 [24:39<00:00, 25.96s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def topn_recommendations(scores: np.ndarray, topn: int = 10) -> np.ndarray:\n",
    "    recommendations = np.apply_along_axis(topidx, 1, scores, topn)\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "def topidx(a: np.ndarray, topn: int) -> np.ndarray:\n",
    "    parted = np.argpartition(a, -topn)[-topn:]\n",
    "    return parted[np.argsort(-a[parted])]\n",
    "\n",
    "\n",
    "recs = list()\n",
    "batch_size = 1000\n",
    "\n",
    "for i in tqdm(range(0, len(holdout), batch_size)):\n",
    "    cur_sessions = holdout.session_id[i : i + batch_size]\n",
    "    cur_mtx = val_mtx[cur_sessions, :]\n",
    "    cur_scores = np.array((csr_matrix(cur_mtx @ vh.T) @ vh))\n",
    "    cur_recs = topn_recommendations(cur_scores, topn=k)\n",
    "    recs.append(cur_recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bf5e4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ndcg': np.float64(0.013682537689545214),\n",
       " 'hitrate': np.float64(0.02544010682033803)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics(np.concat(recs), holdout.item_id.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
